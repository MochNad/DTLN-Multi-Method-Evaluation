{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d8d1d81",
   "metadata": {},
   "source": [
    "# üéµ DTLN Multi-Method Audio Evaluation\n",
    "**Comprehensive Comparison of 4 Audio Processing Methods**\n",
    "\n",
    "Interactive notebook for noise suppression experiments comparing DTLN neural network with traditional DSP methods.\n",
    "\n",
    "## üéØ Four Evaluation Methods:\n",
    "\n",
    "1. **Deterministic (DTLN)** - Fixed uploaded noise + DTLN neural network\n",
    "2. **Stochastic (DTLN)** - Random synthetic noise + DTLN neural network\n",
    "3. **Traditional-Manual (DSP)** - Spectral Subtraction & Wiener Filter (research-based)\n",
    "4. **Traditional-Library (DSP)** - noisereduce library (industry standard)\n",
    "\n",
    "## üìä Evaluation Features:\n",
    "\n",
    "- **SNR Range:** -5, 0, 5, 10 dB (4 levels)\n",
    "- **Metrics:** STOI, PESQ, MSE, MRE with baseline comparison\n",
    "- **Noise Types:** Gaussian, White, Mixed\n",
    "- **Fair Comparison:** All methods use blind noise estimation (no ground truth leakage)\n",
    "- **Comprehensive Visualization:** Waveforms, spectrograms, metrics charts\n",
    "- **Excel Export:** Multi-sheet results with statistics\n",
    "\n",
    "**Quick Start:**\n",
    "1. Install packages ‚Üí 2. Upload models & audio ‚Üí 3. Run experiments ‚Üí 4. Download results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì¶ Step 1: Install Required Packages { display-mode: \"form\" }\n",
    "#@markdown This cell installs all necessary Python packages for the evaluation.\n",
    "\n",
    "# Install Required Packages\n",
    "!pip install -q numpy scipy librosa soundfile onnxruntime matplotlib pystoi pesq openpyxl pandas noisereduce\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import onnxruntime\n",
    "from scipy import signal\n",
    "from pystoi import stoi\n",
    "from pesq import pesq\n",
    "import os\n",
    "import shutil\n",
    "from google.colab import files\n",
    "from IPython.display import display, Audio\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import noisereduce as nr\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup directories\n",
    "os.makedirs('pretrained_model', exist_ok=True)\n",
    "os.makedirs('uploads', exist_ok=True)\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('results/audio', exist_ok=True)\n",
    "os.makedirs('results/spectrograms', exist_ok=True)\n",
    "os.makedirs('results/metrics', exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")\n",
    "print(\"‚úÖ Directory structure created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28080fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ü§ñ Step 2: Download DTLN Models { display-mode: \"form\" }\n",
    "#@markdown Auto-download pre-trained DTLN models from GitHub repository.\n",
    "\n",
    "# Auto-download DTLN Models\n",
    "import urllib.request\n",
    "import ssl\n",
    "\n",
    "def download_dtln_models():\n",
    "    models = {\n",
    "        'model_1.onnx': 'https://github.com/breizhn/DTLN/raw/master/pretrained_model/model_1.onnx',\n",
    "        'model_2.onnx': 'https://github.com/breizhn/DTLN/raw/master/pretrained_model/model_2.onnx'\n",
    "    }\n",
    "    \n",
    "    ssl_context = ssl.create_default_context()\n",
    "    ssl_context.check_hostname = False\n",
    "    ssl_context.verify_mode = ssl.CERT_NONE\n",
    "    \n",
    "    print(\"üì• Downloading DTLN models from GitHub...\")\n",
    "    \n",
    "    for model_name, url in models.items():\n",
    "        model_path = f'pretrained_model/{model_name}'\n",
    "        \n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"‚úì {model_name} already exists\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            print(f\"‚¨áÔ∏è  Downloading {model_name}...\", end=' ')\n",
    "            urllib.request.urlretrieve(url, model_path)\n",
    "            file_size = os.path.getsize(model_path) / (1024 * 1024)\n",
    "            print(f\"‚úÖ Done ({file_size:.2f} MB)\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Download models\n",
    "download_success = download_dtln_models()\n",
    "\n",
    "if not download_success:\n",
    "    print(\"\\n‚ö†Ô∏è  Auto-download failed. Please upload models manually.\")\n",
    "    uploaded = files.upload()\n",
    "    for filename in uploaded.keys():\n",
    "        shutil.move(filename, f'pretrained_model/{filename}')\n",
    "\n",
    "# Load models\n",
    "if os.path.exists('pretrained_model/model_1.onnx') and os.path.exists('pretrained_model/model_2.onnx'):\n",
    "    BLOCK_LEN = 512\n",
    "    BLOCK_SHIFT = 128\n",
    "    SAMPLE_RATE = 16000\n",
    "    \n",
    "    print(\"\\n‚öôÔ∏è  Loading ONNX models...\")\n",
    "    interpreter_1 = onnxruntime.InferenceSession('pretrained_model/model_1.onnx')\n",
    "    interpreter_2 = onnxruntime.InferenceSession('pretrained_model/model_2.onnx')\n",
    "    model_input_names_1 = [inp.name for inp in interpreter_1.get_inputs()]\n",
    "    model_input_names_2 = [inp.name for inp in interpreter_2.get_inputs()]\n",
    "    model_inputs_1 = {inp.name: np.zeros([dim if isinstance(dim, int) else 1 for dim in inp.shape], dtype=np.float32) for inp in interpreter_1.get_inputs()}\n",
    "    model_inputs_2 = {inp.name: np.zeros([dim if isinstance(dim, int) else 1 for dim in inp.shape], dtype=np.float32) for inp in interpreter_2.get_inputs()}\n",
    "    \n",
    "    print(f\"‚úÖ DTLN models loaded successfully!\")\n",
    "    print(f\"   Configuration: BLOCK_LEN={BLOCK_LEN}, BLOCK_SHIFT={BLOCK_SHIFT}, SAMPLE_RATE={SAMPLE_RATE}Hz\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"DTLN model files are missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7295be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üé§ Step 3: Upload Audio Files { display-mode: \"form\" }\n",
    "#@markdown Upload clean speech and noise audio files for evaluation.\n",
    "\n",
    "# Upload Audio Files\n",
    "print(\"üì§ Upload Clean Audio (required):\")\n",
    "uploaded_clean = files.upload()\n",
    "audio_clean_file = list(uploaded_clean.keys())[0]\n",
    "shutil.move(audio_clean_file, f'uploads/{audio_clean_file}')\n",
    "\n",
    "print(\"\\nüì§ Upload Noise Audio (optional, for deterministic method):\")\n",
    "uploaded_noise = files.upload()\n",
    "audio_noise_file = list(uploaded_noise.keys())[0] if uploaded_noise else None\n",
    "if audio_noise_file:\n",
    "    shutil.move(audio_noise_file, f'uploads/{audio_noise_file}')\n",
    "    print(f\"‚úì Noise file uploaded\")\n",
    "else:\n",
    "    print(\"‚úì Skip - will use synthetic noise\")\n",
    "\n",
    "# Load audio\n",
    "def load_audio(path, sr=16000):\n",
    "    audio, orig_sr = sf.read(path)\n",
    "    if len(audio.shape) > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    if orig_sr != sr:\n",
    "        num_samples = int(len(audio) * sr / orig_sr)\n",
    "        audio = signal.resample(audio, num_samples)\n",
    "    return audio, sr\n",
    "\n",
    "audio_clean, sr = load_audio(f'uploads/{audio_clean_file}', SAMPLE_RATE)\n",
    "audio_noise_uploaded = load_audio(f'uploads/{audio_noise_file}', SAMPLE_RATE)[0] if audio_noise_file else None\n",
    "\n",
    "print(f\"\\n‚úÖ Clean audio loaded: {len(audio_clean)/sr:.2f}s @ {sr}Hz\")\n",
    "if audio_noise_uploaded is not None:\n",
    "    print(f\"‚úÖ Noise audio loaded: {len(audio_noise_uploaded)/sr:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8cded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title ‚öôÔ∏è Step 4: Load Processing Functions { display-mode: \"form\" }\n",
    "#@markdown Initialize all noise generation, processing methods, and metrics calculation functions.\n",
    "\n",
    "# ============== NOISE GENERATION & SNR CALCULATION ==============\n",
    "def calculate_rms(signal):\n",
    "    \"\"\"Calculate Root Mean Square (RMS) power\"\"\"\n",
    "    return np.sqrt(np.mean(signal ** 2))\n",
    "\n",
    "def calculate_snr_db(clean, noisy):\n",
    "    \"\"\"Calculate actual SNR in dB using RMS power\"\"\"\n",
    "    clean_power = calculate_rms(clean) ** 2\n",
    "    noise_power = calculate_rms(noisy - clean) ** 2\n",
    "    if noise_power < 1e-10:\n",
    "        return float('inf')\n",
    "    return 10 * np.log10(clean_power / noise_power)\n",
    "\n",
    "def add_gaussian_noise(audio, target_snr_db):\n",
    "    \"\"\"Add Gaussian noise at specified SNR\"\"\"\n",
    "    audio_power = calculate_rms(audio) ** 2\n",
    "    if audio_power < 1e-10:\n",
    "        audio_power = 1e-10\n",
    "    noise_power = audio_power / (10 ** (target_snr_db / 10))\n",
    "    noise = np.random.normal(0, np.sqrt(noise_power), len(audio))\n",
    "    mixed = audio + noise\n",
    "    actual_snr = calculate_snr_db(audio, mixed)\n",
    "    return mixed, noise, actual_snr\n",
    "\n",
    "def add_white_noise(audio, target_snr_db):\n",
    "    \"\"\"Add white noise at specified SNR\"\"\"\n",
    "    audio_power = calculate_rms(audio) ** 2\n",
    "    if audio_power < 1e-10:\n",
    "        audio_power = 1e-10\n",
    "    noise_power = audio_power / (10 ** (target_snr_db / 10))\n",
    "    noise = np.random.uniform(-1, 1, len(audio))\n",
    "    noise = noise / calculate_rms(noise) * np.sqrt(noise_power)\n",
    "    mixed = audio + noise\n",
    "    actual_snr = calculate_snr_db(audio, mixed)\n",
    "    return mixed, noise, actual_snr\n",
    "\n",
    "def mix_audio_with_snr(clean, noise, target_snr_db):\n",
    "    \"\"\"Mix clean audio with noise at specified SNR\"\"\"\n",
    "    if len(noise) < len(clean):\n",
    "        repeats = int(np.ceil(len(clean) / len(noise)))\n",
    "        noise = np.tile(noise, repeats)[:len(clean)]\n",
    "    else:\n",
    "        noise = noise[:len(clean)]\n",
    "    \n",
    "    clean_power = calculate_rms(clean) ** 2\n",
    "    noise_power_original = calculate_rms(noise) ** 2\n",
    "    \n",
    "    if noise_power_original < 1e-10:\n",
    "        noise_power_original = 1e-10\n",
    "    if clean_power < 1e-10:\n",
    "        clean_power = 1e-10\n",
    "    \n",
    "    target_noise_power = clean_power / (10 ** (target_snr_db / 10))\n",
    "    scale = np.sqrt(target_noise_power / noise_power_original)\n",
    "    scaled_noise = noise * scale\n",
    "    mixed = clean + scaled_noise\n",
    "    \n",
    "    max_val = np.max(np.abs(mixed))\n",
    "    if max_val > 1.0:\n",
    "        mixed = mixed / max_val\n",
    "        scaled_noise = scaled_noise / max_val\n",
    "    \n",
    "    actual_snr = calculate_snr_db(clean, mixed)\n",
    "    return mixed, scaled_noise, actual_snr\n",
    "\n",
    "# ============== PROCESSING METHODS ==============\n",
    "def process_dtln(audio):\n",
    "    \"\"\"Process audio using DTLN ONNX models\"\"\"\n",
    "    for inp in interpreter_1.get_inputs():\n",
    "        model_inputs_1[inp.name] = np.zeros([dim if isinstance(dim, int) else 1 for dim in inp.shape], dtype=np.float32)\n",
    "    for inp in interpreter_2.get_inputs():\n",
    "        model_inputs_2[inp.name] = np.zeros([dim if isinstance(dim, int) else 1 for dim in inp.shape], dtype=np.float32)\n",
    "    \n",
    "    out_file = np.zeros(len(audio))\n",
    "    in_buffer = np.zeros(BLOCK_LEN, dtype='float32')\n",
    "    out_buffer = np.zeros(BLOCK_LEN, dtype='float32')\n",
    "    num_blocks = (len(audio) - (BLOCK_LEN - BLOCK_SHIFT)) // BLOCK_SHIFT\n",
    "    \n",
    "    for idx in range(num_blocks):\n",
    "        in_buffer[:-BLOCK_SHIFT] = in_buffer[BLOCK_SHIFT:]\n",
    "        in_buffer[-BLOCK_SHIFT:] = audio[idx*BLOCK_SHIFT:(idx*BLOCK_SHIFT)+BLOCK_SHIFT]\n",
    "        \n",
    "        in_fft = np.fft.rfft(in_buffer)\n",
    "        in_mag, in_phase = np.abs(in_fft), np.angle(in_fft)\n",
    "        \n",
    "        model_inputs_1[model_input_names_1[0]] = np.reshape(in_mag, (1,1,-1)).astype('float32')\n",
    "        out_1 = interpreter_1.run(None, model_inputs_1)\n",
    "        model_inputs_1[model_input_names_1[1]] = out_1[1]\n",
    "        \n",
    "        est_complex = in_mag * out_1[0] * np.exp(1j * in_phase)\n",
    "        est_block = np.fft.irfft(est_complex)\n",
    "        \n",
    "        model_inputs_2[model_input_names_2[0]] = np.reshape(est_block, (1,1,-1)).astype('float32')\n",
    "        out_2 = interpreter_2.run(None, model_inputs_2)\n",
    "        model_inputs_2[model_input_names_2[1]] = out_2[1]\n",
    "        \n",
    "        out_buffer[:-BLOCK_SHIFT] = out_buffer[BLOCK_SHIFT:]\n",
    "        out_buffer[-BLOCK_SHIFT:] = 0\n",
    "        out_buffer += np.squeeze(out_2[0])\n",
    "        out_file[idx*BLOCK_SHIFT:(idx*BLOCK_SHIFT)+BLOCK_SHIFT] = out_buffer[:BLOCK_SHIFT]\n",
    "    return out_file\n",
    "\n",
    "def spectral_subtraction_manual(noisy_audio, alpha=2.0, beta=0.01, sr=16000):\n",
    "    \"\"\"\n",
    "    Spectral Subtraction based on Boll (1979)\n",
    "    Reference: \"Suppression of acoustic noise in speech using spectral subtraction\"\n",
    "    IEEE Transactions on Acoustics, Speech, and Signal Processing\n",
    "    \"\"\"\n",
    "    nperseg = 512\n",
    "    noverlap = 384\n",
    "    \n",
    "    f, t, Zxx = signal.stft(noisy_audio, fs=sr, nperseg=nperseg, noverlap=noverlap)\n",
    "    \n",
    "    # Estimate noise from initial frames (first 10 frames)\n",
    "    noise_frames = 10\n",
    "    noise_spectrum = np.mean(np.abs(Zxx[:, :noise_frames]) ** 2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Spectral subtraction\n",
    "    magnitude = np.abs(Zxx)\n",
    "    phase = np.angle(Zxx)\n",
    "    \n",
    "    # Power spectral subtraction with over-subtraction factor (alpha) and spectral floor (beta)\n",
    "    clean_magnitude_squared = np.maximum(\n",
    "        magnitude ** 2 - alpha * noise_spectrum,\n",
    "        beta * magnitude ** 2\n",
    "    )\n",
    "    clean_magnitude = np.sqrt(clean_magnitude_squared)\n",
    "    \n",
    "    clean_stft = clean_magnitude * np.exp(1j * phase)\n",
    "    _, clean_audio = signal.istft(clean_stft, fs=sr, nperseg=nperseg, noverlap=noverlap)\n",
    "    \n",
    "    # Match length\n",
    "    if len(clean_audio) > len(noisy_audio):\n",
    "        clean_audio = clean_audio[:len(noisy_audio)]\n",
    "    elif len(clean_audio) < len(noisy_audio):\n",
    "        clean_audio = np.pad(clean_audio, (0, len(noisy_audio) - len(clean_audio)))\n",
    "    \n",
    "    return clean_audio\n",
    "\n",
    "def wiener_filter_manual(noisy_audio, sr=16000):\n",
    "    \"\"\"\n",
    "    Wiener Filter based on Wiener (1949) and Lim & Oppenheim (1979)\n",
    "    Reference: \"Enhancement and bandwidth compression of noisy speech\"\n",
    "    Proceedings of the IEEE\n",
    "    \"\"\"\n",
    "    nperseg = 512\n",
    "    noverlap = 384\n",
    "    \n",
    "    f, t, Zxx = signal.stft(noisy_audio, fs=sr, nperseg=nperseg, noverlap=noverlap)\n",
    "    \n",
    "    # Estimate noise power from initial frames\n",
    "    noise_frames = 10\n",
    "    noise_power = np.mean(np.abs(Zxx[:, :noise_frames]) ** 2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Wiener filtering\n",
    "    noisy_power = np.abs(Zxx) ** 2\n",
    "    \n",
    "    # Wiener gain with SNR estimation\n",
    "    snr_prior = np.maximum(noisy_power - noise_power, 0) / (noise_power + 1e-10)\n",
    "    wiener_gain = snr_prior / (snr_prior + 1)\n",
    "    \n",
    "    # Apply minimum gain threshold\n",
    "    wiener_gain = np.maximum(wiener_gain, 0.1)\n",
    "    \n",
    "    clean_stft = Zxx * wiener_gain\n",
    "    _, clean_audio = signal.istft(clean_stft, fs=sr, nperseg=nperseg, noverlap=noverlap)\n",
    "    \n",
    "    # Match length\n",
    "    if len(clean_audio) > len(noisy_audio):\n",
    "        clean_audio = clean_audio[:len(noisy_audio)]\n",
    "    elif len(clean_audio) < len(noisy_audio):\n",
    "        clean_audio = np.pad(clean_audio, (0, len(noisy_audio) - len(clean_audio)))\n",
    "    \n",
    "    return clean_audio\n",
    "\n",
    "def process_traditional_library(noisy_audio, sr=16000):\n",
    "    \"\"\"\n",
    "    Library-based noise reduction using noisereduce\n",
    "    Algorithm: Spectral Gating (similar to Audacity)\n",
    "    \"\"\"\n",
    "    reduced_audio = nr.reduce_noise(\n",
    "        y=noisy_audio,\n",
    "        sr=sr,\n",
    "        stationary=True,\n",
    "        prop_decrease=1.0\n",
    "    )\n",
    "    \n",
    "    if len(reduced_audio) != len(noisy_audio):\n",
    "        if len(reduced_audio) > len(noisy_audio):\n",
    "            reduced_audio = reduced_audio[:len(noisy_audio)]\n",
    "        else:\n",
    "            reduced_audio = np.pad(reduced_audio, (0, len(noisy_audio) - len(reduced_audio)))\n",
    "    \n",
    "    return reduced_audio\n",
    "\n",
    "# ============== METRICS CALCULATION ==============\n",
    "def calculate_metrics(clean, processed, fs=16000):\n",
    "    \"\"\"Calculate evaluation metrics with time-alignment\"\"\"\n",
    "    metrics = {}\n",
    "    \n",
    "    min_len = min(len(clean), len(processed))\n",
    "    clean = clean[:min_len]\n",
    "    processed = processed[:min_len]\n",
    "    \n",
    "    clean = np.nan_to_num(clean, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    processed = np.nan_to_num(processed, nan=0.0, posinf=1.0, neginf=-1.0)\n",
    "    \n",
    "    if np.sum(np.abs(clean)) == 0:\n",
    "        clean = clean + 1e-10\n",
    "    if np.sum(np.abs(processed)) == 0:\n",
    "        processed = processed + 1e-10\n",
    "    \n",
    "    # Time-alignment\n",
    "    from scipy.signal import correlate\n",
    "    max_lag_search = min(512, len(processed) // 4)\n",
    "    correlation = correlate(clean, processed, mode='full', method='fft')\n",
    "    center = len(processed) - 1\n",
    "    search_start = max(0, center - 50)\n",
    "    search_end = min(len(correlation), center + max_lag_search)\n",
    "    restricted_correlation = correlation[search_start:search_end]\n",
    "    lag = np.argmax(restricted_correlation) + search_start - center\n",
    "    \n",
    "    if lag > 0:\n",
    "        processed_aligned = processed[lag:]\n",
    "        clean_aligned = clean[:len(processed_aligned)]\n",
    "    elif lag < 0:\n",
    "        clean_aligned = clean[-lag:]\n",
    "        processed_aligned = processed[:len(clean_aligned)]\n",
    "    else:\n",
    "        clean_aligned = clean\n",
    "        processed_aligned = processed\n",
    "    \n",
    "    min_len_aligned = min(len(clean_aligned), len(processed_aligned))\n",
    "    clean_aligned = clean_aligned[:min_len_aligned]\n",
    "    processed_aligned = processed_aligned[:min_len_aligned]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    try:\n",
    "        metrics['stoi'] = stoi(clean_aligned, processed_aligned, fs, extended=False)\n",
    "        if np.isnan(metrics['stoi']) or np.isinf(metrics['stoi']):\n",
    "            metrics['stoi'] = 0.0\n",
    "    except:\n",
    "        metrics['stoi'] = 0.0\n",
    "    \n",
    "    try:\n",
    "        if fs == 16000:\n",
    "            metrics['pesq'] = pesq(fs, clean_aligned, processed_aligned, 'wb')\n",
    "        else:\n",
    "            metrics['pesq'] = 0.0\n",
    "        if np.isnan(metrics['pesq']) or np.isinf(metrics['pesq']):\n",
    "            metrics['pesq'] = 0.0\n",
    "    except:\n",
    "        metrics['pesq'] = 0.0\n",
    "    \n",
    "    metrics['mse'] = np.mean((clean_aligned - processed_aligned) ** 2)\n",
    "    if np.isnan(metrics['mse']) or np.isinf(metrics['mse']):\n",
    "        metrics['mse'] = 0.0\n",
    "    \n",
    "    amplitude_threshold = 0.01\n",
    "    mask = np.abs(clean_aligned) > amplitude_threshold\n",
    "    if np.sum(mask) > 0:\n",
    "        clean_masked = clean_aligned[mask]\n",
    "        processed_masked = processed_aligned[mask]\n",
    "        epsilon = 1e-10\n",
    "        relative_error = np.abs(clean_masked - processed_masked) / (np.abs(clean_masked) + epsilon)\n",
    "        relative_error = np.clip(relative_error, 0, 10)\n",
    "        metrics['mre'] = np.mean(relative_error)\n",
    "    else:\n",
    "        metrics['mre'] = 0.0\n",
    "    \n",
    "    if np.isnan(metrics['mre']) or np.isinf(metrics['mre']):\n",
    "        metrics['mre'] = 0.0\n",
    "    \n",
    "    metrics['lag_samples'] = lag\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "print(\"‚úÖ All processing functions loaded!\")\n",
    "print(\"\\nüìä Available Methods:\")\n",
    "print(\"   1. Deterministic (DTLN)\")\n",
    "print(\"   2. Stochastic (DTLN)\")\n",
    "print(\"   3. Traditional-Manual (Spectral Subtraction & Wiener)\")\n",
    "print(\"   4. Traditional-Library (noisereduce)\")\n",
    "print(\"\\nüìê SNR Range: -5, 0, 5, 10 dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31880794",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Single Experiment Mode\n",
    "**Test individual method with complete before/after analysis**\n",
    "\n",
    "Run a single experiment to see detailed visualizations including:\n",
    "- Waveforms (Clean, Noise, Before, After, Overlay)\n",
    "- Spectrograms for all stages\n",
    "- Reconstruction error analysis\n",
    "- Metrics comparison chart\n",
    "- Audio playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üß™ Run Single Experiment { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üîß **Configuration**\n",
    "\n",
    "run_single = False  #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üéØ **Method Selection**\n",
    "single_method = \"deterministic\"  #@param [\"deterministic\", \"stochastic\", \"traditional_manual\", \"traditional_library\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üõ†Ô∏è **DSP Algorithm** (for Traditional-Manual only)\n",
    "single_dsp_method = \"spectral_subtraction\"  #@param [\"spectral_subtraction\", \"wiener\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üîä **Noise Type** (for Stochastic/Traditional)\n",
    "single_noise_type = \"gaussian\"  #@param [\"gaussian\", \"white\", \"mixed\", \"uploaded\"]\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üìä **SNR Level** (dB)\n",
    "single_snr = 10  #@param {type:\"slider\", min:-5, max:10, step:5}\n",
    "\n",
    "if run_single:\n",
    "    print(\"=\"*100)\n",
    "    print(\"üß™ SINGLE EXPERIMENT - FULL ANALYSIS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Generate noisy audio based on method\n",
    "    if single_method == 'deterministic':\n",
    "        if audio_noise_uploaded is None:\n",
    "            print(\"‚ùå ERROR: Deterministic requires uploaded noise file!\")\n",
    "            raise ValueError(\"Upload noise file first\")\n",
    "        mixed_audio, used_noise, actual_snr = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)\n",
    "        method_label = \"Deterministic (DTLN)\"\n",
    "        noise_label = \"Uploaded\"\n",
    "        \n",
    "    elif single_method == 'stochastic':\n",
    "        if single_noise_type == 'gaussian':\n",
    "            mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "            noise_label = \"Gaussian\"\n",
    "        elif single_noise_type == 'white':\n",
    "            mixed_audio, used_noise, actual_snr = add_white_noise(audio_clean, single_snr)\n",
    "            noise_label = \"White\"\n",
    "        elif single_noise_type == 'mixed':\n",
    "            if audio_noise_uploaded is not None:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                noise_uploaded_scaled = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white + noise_uploaded_scaled) / 3.0\n",
    "            else:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white) / 2.0\n",
    "            mixed_audio = audio_clean + used_noise\n",
    "            actual_snr = calculate_snr_db(audio_clean, mixed_audio)\n",
    "            noise_label = \"Mixed\"\n",
    "        elif single_noise_type == 'uploaded':\n",
    "            if audio_noise_uploaded is None:\n",
    "                print(\"‚ö†Ô∏è  No uploaded noise, using Gaussian\")\n",
    "                mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "                noise_label = \"Gaussian\"\n",
    "            else:\n",
    "                mixed_audio, used_noise, actual_snr = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)\n",
    "                noise_label = \"Uploaded\"\n",
    "        method_label = \"Stochastic (DTLN)\"\n",
    "        \n",
    "    elif single_method == 'traditional_manual':\n",
    "        if single_noise_type == 'gaussian':\n",
    "            mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "            noise_label = \"Gaussian\"\n",
    "        elif single_noise_type == 'white':\n",
    "            mixed_audio, used_noise, actual_snr = add_white_noise(audio_clean, single_snr)\n",
    "            noise_label = \"White\"\n",
    "        elif single_noise_type == 'mixed':\n",
    "            if audio_noise_uploaded is not None:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                noise_uploaded_scaled = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white + noise_uploaded_scaled) / 3.0\n",
    "            else:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white) / 2.0\n",
    "            mixed_audio = audio_clean + used_noise\n",
    "            actual_snr = calculate_snr_db(audio_clean, mixed_audio)\n",
    "            noise_label = \"Mixed\"\n",
    "        elif single_noise_type == 'uploaded':\n",
    "            if audio_noise_uploaded is None:\n",
    "                print(\"‚ö†Ô∏è  No uploaded noise, using Gaussian\")\n",
    "                mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "                noise_label = \"Gaussian\"\n",
    "            else:\n",
    "                mixed_audio, used_noise, actual_snr = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)\n",
    "                noise_label = \"Uploaded\"\n",
    "        method_label = f\"Traditional-Manual ({single_dsp_method.replace('_', ' ').title()})\"\n",
    "        \n",
    "    else:  # traditional_library\n",
    "        if single_noise_type == 'gaussian':\n",
    "            mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "            noise_label = \"Gaussian\"\n",
    "        elif single_noise_type == 'white':\n",
    "            mixed_audio, used_noise, actual_snr = add_white_noise(audio_clean, single_snr)\n",
    "            noise_label = \"White\"\n",
    "        elif single_noise_type == 'mixed':\n",
    "            if audio_noise_uploaded is not None:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                noise_uploaded_scaled = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white + noise_uploaded_scaled) / 3.0\n",
    "            else:\n",
    "                noise_gaussian = add_gaussian_noise(audio_clean, single_snr)[1]\n",
    "                noise_white = add_white_noise(audio_clean, single_snr)[1]\n",
    "                used_noise = (noise_gaussian + noise_white) / 2.0\n",
    "            mixed_audio = audio_clean + used_noise\n",
    "            actual_snr = calculate_snr_db(audio_clean, mixed_audio)\n",
    "            noise_label = \"Mixed\"\n",
    "        elif single_noise_type == 'uploaded':\n",
    "            if audio_noise_uploaded is None:\n",
    "                print(\"‚ö†Ô∏è  No uploaded noise, using Gaussian\")\n",
    "                mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, single_snr)\n",
    "                noise_label = \"Gaussian\"\n",
    "            else:\n",
    "                mixed_audio, used_noise, actual_snr = mix_audio_with_snr(audio_clean, audio_noise_uploaded, single_snr)\n",
    "                noise_label = \"Uploaded\"\n",
    "        method_label = \"Traditional-Library (noisereduce)\"\n",
    "    \n",
    "    print(f\"Method: {method_label}\")\n",
    "    print(f\"Noise: {noise_label}\")\n",
    "    print(f\"Target SNR: {single_snr} dB | Actual SNR: {actual_snr:.2f} dB\")\n",
    "    print()\n",
    "    \n",
    "    # Calculate baseline\n",
    "    print(\"‚öôÔ∏è  Calculating baseline metrics...\")\n",
    "    baseline = calculate_metrics(audio_clean, mixed_audio, SAMPLE_RATE)\n",
    "    \n",
    "    # Process audio\n",
    "    print(\"‚öôÔ∏è  Processing audio...\")\n",
    "    start = time.time()\n",
    "    if single_method in ['deterministic', 'stochastic']:\n",
    "        audio_processed = process_dtln(mixed_audio)\n",
    "    elif single_method == 'traditional_manual':\n",
    "        if single_dsp_method == 'spectral_subtraction':\n",
    "            audio_processed = spectral_subtraction_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "        else:\n",
    "            audio_processed = wiener_filter_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "    else:  # traditional_library\n",
    "        audio_processed = process_traditional_library(mixed_audio, sr=SAMPLE_RATE)\n",
    "    proc_time = time.time() - start\n",
    "    \n",
    "    # Calculate processed metrics\n",
    "    metrics = calculate_metrics(audio_clean, audio_processed, SAMPLE_RATE)\n",
    "    \n",
    "    # Helper function to get status and color\n",
    "    def get_metric_status(metric_name, value):\n",
    "        if metric_name == 'STOI':\n",
    "            # Range: 0-1 (Higher is better)\n",
    "            if value >= 0.9: return 'üü¢ Excellent', '#10b981'\n",
    "            elif value >= 0.7: return 'üü° Good', '#f59e0b'\n",
    "            elif value >= 0.5: return 'üü† Fair', '#fb923c'\n",
    "            else: return 'üî¥ Poor', '#ef4444'\n",
    "        elif metric_name == 'PESQ':\n",
    "            # Range: -0.5 to 4.5 (Higher is better)\n",
    "            if value >= 3.5: return 'üü¢ Excellent', '#10b981'\n",
    "            elif value >= 2.5: return 'üü° Good', '#f59e0b'\n",
    "            elif value >= 1.5: return 'üü† Fair', '#fb923c'\n",
    "            else: return 'üî¥ Poor', '#ef4444'\n",
    "        elif metric_name == 'MSE':\n",
    "            # Range: 0-‚àû (Lower is better)\n",
    "            if value <= 0.001: return 'üü¢ Excellent', '#10b981'\n",
    "            elif value <= 0.01: return 'üü° Good', '#f59e0b'\n",
    "            elif value <= 0.1: return 'üü† Fair', '#fb923c'\n",
    "            else: return 'üî¥ Poor', '#ef4444'\n",
    "        elif metric_name == 'MRE':\n",
    "            # Range: 0-10 (Lower is better)\n",
    "            if value <= 0.1: return 'üü¢ Excellent', '#10b981'\n",
    "            elif value <= 0.5: return 'üü° Good', '#f59e0b'\n",
    "            elif value <= 1.0: return 'üü† Fair', '#fb923c'\n",
    "            else: return 'üî¥ Poor', '#ef4444'\n",
    "    \n",
    "    # Display metrics with status\n",
    "    print(f\"\\n{'='*110}\")\n",
    "    print(f\"üìä EVALUATION RESULTS\")\n",
    "    print(f\"{'='*110}\")\n",
    "    print(f\"Processing Time: {proc_time:.3f}s\")\n",
    "    print()\n",
    "    print(f\"{'Metric':<12} {'Range':<20} {'Baseline':<12} {'Status':<20} {'Processed':<12} {'Status':<20}\")\n",
    "    print(f\"{'-'*110}\")\n",
    "    \n",
    "    stoi_base_status, _ = get_metric_status('STOI', baseline['stoi'])\n",
    "    stoi_proc_status, _ = get_metric_status('STOI', metrics['stoi'])\n",
    "    print(f\"{'STOI':<12} {'0-1 (‚Üë better)':<20} {baseline['stoi']:<12.4f} {stoi_base_status:<20} {metrics['stoi']:<12.4f} {stoi_proc_status:<20}\")\n",
    "    \n",
    "    pesq_base_status, _ = get_metric_status('PESQ', baseline['pesq'])\n",
    "    pesq_proc_status, _ = get_metric_status('PESQ', metrics['pesq'])\n",
    "    print(f\"{'PESQ':<12} {'-0.5-4.5 (‚Üë better)':<20} {baseline['pesq']:<12.4f} {pesq_base_status:<20} {metrics['pesq']:<12.4f} {pesq_proc_status:<20}\")\n",
    "    \n",
    "    mse_base_status, _ = get_metric_status('MSE', baseline['mse'])\n",
    "    mse_proc_status, _ = get_metric_status('MSE', metrics['mse'])\n",
    "    print(f\"{'MSE':<12} {'0-‚àû (‚Üì better)':<20} {baseline['mse']:<12.4f} {mse_base_status:<20} {metrics['mse']:<12.4f} {mse_proc_status:<20}\")\n",
    "    \n",
    "    mre_base_status, _ = get_metric_status('MRE', baseline['mre'])\n",
    "    mre_proc_status, _ = get_metric_status('MRE', metrics['mre'])\n",
    "    print(f\"{'MRE':<12} {'0-10 (‚Üì better)':<20} {baseline['mre']:<12.4f} {mre_base_status:<20} {metrics['mre']:<12.4f} {mre_proc_status:<20}\")\n",
    "    print(f\"{'='*110}\")\n",
    "    \n",
    "    # Audio players\n",
    "    print(\"\\nüéµ Audio Playback:\")\n",
    "    print(\"Clean Audio:\")\n",
    "    display(Audio(audio_clean, rate=SAMPLE_RATE))\n",
    "    print(\"\\nNoisy Audio (Before):\")\n",
    "    display(Audio(mixed_audio, rate=SAMPLE_RATE))\n",
    "    print(\"\\nProcessed Audio (After):\")\n",
    "    display(Audio(audio_processed, rate=SAMPLE_RATE))\n",
    "    \n",
    "    # ============== FULL VISUALIZATION ==============\n",
    "    time_axis = np.linspace(0, len(audio_clean)/SAMPLE_RATE, len(audio_clean))\n",
    "    \n",
    "    # Figure 1: Waveforms + Spectrograms (5 rows)\n",
    "    fig = plt.figure(figsize=(20, 18))\n",
    "    gs = fig.add_gridspec(5, 4, hspace=0.4, wspace=0.3)\n",
    "    fig.suptitle(f'{method_label} | {noise_label} Noise | SNR={actual_snr:.1f}dB', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Row 1: Clean\n",
    "    ax = fig.add_subplot(gs[0, :2])\n",
    "    ax.plot(time_axis, audio_clean, linewidth=0.5, color='#10b981', alpha=0.9)\n",
    "    ax.set_title('Clean Audio - Waveform', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0, 2:])\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_clean)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
    "    ax.set_title('Clean Audio - Spectrogram', fontweight='bold', fontsize=12)\n",
    "    plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    \n",
    "    # Row 2: Noise\n",
    "    ax = fig.add_subplot(gs[1, :2])\n",
    "    ax.plot(time_axis[:len(used_noise)], used_noise, linewidth=0.5, color='#f59e0b', alpha=0.9)\n",
    "    ax.set_title('Noise - Waveform', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    \n",
    "    ax = fig.add_subplot(gs[1, 2:])\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(used_noise)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
    "    ax.set_title('Noise - Spectrogram', fontweight='bold', fontsize=12)\n",
    "    plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    \n",
    "    # Row 3: Noisy (Before)\n",
    "    ax = fig.add_subplot(gs[2, :2])\n",
    "    ax.plot(time_axis, mixed_audio, linewidth=0.5, color='#ef4444', alpha=0.9)\n",
    "    ax.set_title('Noisy Audio (BEFORE) - Waveform', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    \n",
    "    ax = fig.add_subplot(gs[2, 2:])\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(mixed_audio)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
    "    ax.set_title('Noisy Audio (BEFORE) - Spectrogram', fontweight='bold', fontsize=12)\n",
    "    plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    \n",
    "    # Row 4: Processed (After)\n",
    "    ax = fig.add_subplot(gs[3, :2])\n",
    "    ax.plot(time_axis, audio_processed, linewidth=0.5, color='#3b82f6', alpha=0.9)\n",
    "    ax.set_title('Processed Audio (AFTER) - Waveform', fontweight='bold', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    \n",
    "    ax = fig.add_subplot(gs[3, 2:])\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(audio_processed)), ref=np.max)\n",
    "    img = librosa.display.specshow(D, sr=SAMPLE_RATE, x_axis='time', y_axis='hz', ax=ax, cmap='magma')\n",
    "    ax.set_title('Processed Audio (AFTER) - Spectrogram', fontweight='bold', fontsize=12)\n",
    "    plt.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    \n",
    "    # Row 5: Overlay Before/After + Error\n",
    "    ax = fig.add_subplot(gs[4, :2])\n",
    "    ax.plot(time_axis, mixed_audio, linewidth=0.8, color='#ef4444', alpha=0.6, label='BEFORE (Noisy)')\n",
    "    ax.plot(time_axis, audio_processed, linewidth=0.8, color='#3b82f6', alpha=0.8, label='AFTER (Processed)')\n",
    "    ax.plot(time_axis, audio_clean, linewidth=0.5, color='#10b981', alpha=0.4, label='Reference (Clean)', linestyle='--')\n",
    "    ax.set_title('üîç OVERLAY: Before vs After', fontweight='bold', fontsize=13)\n",
    "    ax.set_xlabel('Time (s)', fontweight='bold')\n",
    "    ax.set_ylabel('Amplitude', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([-1, 1])\n",
    "    ax.legend(fontsize=10, loc='upper right')\n",
    "    ax.set_facecolor('#f8f9fa')\n",
    "    \n",
    "    ax = fig.add_subplot(gs[4, 2:])\n",
    "    difference = audio_clean - audio_processed\n",
    "    ax.plot(time_axis, difference, linewidth=0.6, color='#8b5cf6', alpha=0.8)\n",
    "    ax.fill_between(time_axis, difference, 0, alpha=0.3, color='#8b5cf6')\n",
    "    ax.set_title('üìâ Reconstruction Error', fontweight='bold', fontsize=13)\n",
    "    ax.set_xlabel('Time (s)', fontweight='bold')\n",
    "    ax.set_ylabel('Error', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.axhline(y=0, color='black', linestyle='-', linewidth=1, alpha=0.5)\n",
    "    ax.set_facecolor('#f8f9fa')\n",
    "    \n",
    "    error_mean = np.mean(np.abs(difference))\n",
    "    error_std = np.std(difference)\n",
    "    error_max = np.max(np.abs(difference))\n",
    "    ax.text(0.02, 0.98, f'Mean: {error_mean:.4f}\\nStd: {error_std:.4f}\\nMax: {error_max:.4f}',\n",
    "            transform=ax.transAxes, fontsize=9, va='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    fname = f\"single_{single_method}_{noise_label}_{single_snr}dB\"\n",
    "    plt.savefig(f'results/spectrograms/{fname}_full.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Figure 2: Metrics Bar Chart with Status Colors\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    fig.suptitle(f'Metrics Scoring: {method_label}', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    metrics_data = [\n",
    "        ('STOI\\n(0-1, ‚Üë better)', baseline['stoi'], metrics['stoi'], [0, 1], 'STOI'),\n",
    "        ('PESQ\\n(-0.5-4.5, ‚Üë better)', baseline['pesq'], metrics['pesq'], [-0.5, 4.5], 'PESQ'),\n",
    "        ('MSE\\n(0-‚àû, ‚Üì better)', baseline['mse'], metrics['mse'], None, 'MSE'),\n",
    "        ('MRE\\n(0-10, ‚Üì better)', baseline['mre'], metrics['mre'], [0, 10], 'MRE')\n",
    "    ]\n",
    "    \n",
    "    for idx, (title, base_val, proc_val, ylim, metric_name) in enumerate(metrics_data):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Get colors based on status\n",
    "        _, base_color = get_metric_status(metric_name, base_val)\n",
    "        _, proc_color = get_metric_status(metric_name, proc_val)\n",
    "        \n",
    "        bar1 = ax.bar(['Baseline'], [base_val], color=base_color, alpha=0.6, width=0.6, edgecolor='black', linewidth=1.5)\n",
    "        bar2 = ax.bar(['Processed'], [proc_val], color=proc_color, alpha=0.9, width=0.6, edgecolor='black', linewidth=1.5)\n",
    "        ax.set_title(title, fontweight='bold', fontsize=10)\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "        if ylim:\n",
    "            ax.set_ylim(ylim)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar in [bar1, bar2]:\n",
    "            for b in bar:\n",
    "                height = b.get_height()\n",
    "                ax.text(b.get_x() + b.get_width()/2., height,\n",
    "                       f'{height:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "        \n",
    "        # Add status legend\n",
    "        base_status, _ = get_metric_status(metric_name, base_val)\n",
    "        proc_status, _ = get_metric_status(metric_name, proc_val)\n",
    "        ax.text(0.5, 0.95, f'Baseline: {base_status.split()[0]}\\nProcessed: {proc_status.split()[0]}',\n",
    "                transform=ax.transAxes, ha='center', va='top', fontsize=8,\n",
    "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'results/metrics/{fname}_chart.png', dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Save audio files\n",
    "    sf.write(f'outputs/{fname}_before.wav', mixed_audio, SAMPLE_RATE)\n",
    "    sf.write(f'outputs/{fname}_after.wav', audio_processed, SAMPLE_RATE)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Single experiment completed!\")\n",
    "    print(f\"   Files saved:\")\n",
    "    print(f\"   ‚Ä¢ results/spectrograms/{fname}_full.png\")\n",
    "    print(f\"   ‚Ä¢ results/metrics/{fname}_chart.png\")\n",
    "    print(f\"   ‚Ä¢ outputs/{fname}_before.wav\")\n",
    "    print(f\"   ‚Ä¢ outputs/{fname}_after.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295939d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Batch Evaluation Mode\n",
    "**Comprehensive automated testing with two independent scenarios**\n",
    "\n",
    "### **üåç Scenario 1: Real-world Comparison**\n",
    "- Uses uploaded noise file\n",
    "- Tests: Deterministic (DTLN) + Traditional-Manual (SS & Wiener) + Traditional-Library\n",
    "- **Total: 16 experiments** (4 methods √ó 4 SNR levels)\n",
    "\n",
    "### **üî¨ Scenario 2: Synthetic Comparison**\n",
    "- Uses generated noise (Gaussian, White, Mixed)\n",
    "- Tests: Stochastic (DTLN) + Traditional-Manual (SS & Wiener) + Traditional-Library\n",
    "- **Total: 48 experiments** (4 methods √ó 3 noise types √ó 4 SNR levels)\n",
    "\n",
    "**Grand Total: 64 experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üöÄ Run Batch Evaluation (Two Scenarios) { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### ‚öôÔ∏è **Execution Control**\n",
    "run_batch = False  #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üìù **Note:**\n",
    "#@markdown - Scenario 1 requires uploaded noise file\n",
    "#@markdown - Scenario 2 uses synthetic noise (always available)\n",
    "#@markdown - Results exported to separate Excel files\n",
    "#@markdown - Visualizations saved automatically\n",
    "\n",
    "if run_batch:\n",
    "    SNR_LEVELS = [-5, 0, 5, 10]\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SCENARIO 1: REAL-WORLD COMPARISON (Uploaded Noise Only)\n",
    "    # ============================================================================\n",
    "    print(\"=\"*100)\n",
    "    print(\"üåç SCENARIO 1: REAL-WORLD COMPARISON (Using Uploaded Noise)\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"Comparing: Deterministic (DTLN) vs Traditional-Manual (Both DSP) vs Traditional-Library\")\n",
    "    print(\"Noise Source: Uploaded noise file (same across all methods)\")\n",
    "    print(f\"SNR Levels: {SNR_LEVELS}\")\n",
    "    print()\n",
    "    \n",
    "    realworld_results = []\n",
    "    \n",
    "    if audio_noise_uploaded is not None:\n",
    "        scenario1_configs = []\n",
    "        \n",
    "        # Deterministic (DTLN)\n",
    "        for snr in SNR_LEVELS:\n",
    "            scenario1_configs.append({\n",
    "                'method': 'deterministic',\n",
    "                'snr': snr,\n",
    "                'noise_type': 'uploaded'\n",
    "            })\n",
    "        \n",
    "        # Traditional-Manual: BOTH Spectral Subtraction AND Wiener Filter\n",
    "        for dsp_algo in ['spectral_subtraction', 'wiener']:\n",
    "            for snr in SNR_LEVELS:\n",
    "                scenario1_configs.append({\n",
    "                    'method': 'traditional_manual',\n",
    "                    'snr': snr,\n",
    "                    'noise_type': 'uploaded',\n",
    "                    'dsp_method': dsp_algo\n",
    "                })\n",
    "        \n",
    "        # Traditional-Library\n",
    "        for snr in SNR_LEVELS:\n",
    "            scenario1_configs.append({\n",
    "                'method': 'traditional_library',\n",
    "                'snr': snr,\n",
    "                'noise_type': 'uploaded'\n",
    "            })\n",
    "        \n",
    "        total_s1 = len(scenario1_configs)\n",
    "        print(f\"üîÑ Running {total_s1} experiments...\")\n",
    "        print(f\"   - Deterministic (DTLN): {len(SNR_LEVELS)} configs\")\n",
    "        print(f\"   - Traditional-Manual (Spectral Subtraction): {len(SNR_LEVELS)} configs\")\n",
    "        print(f\"   - Traditional-Manual (Wiener Filter): {len(SNR_LEVELS)} configs\")\n",
    "        print(f\"   - Traditional-Library (noisereduce): {len(SNR_LEVELS)} configs\")\n",
    "        print()\n",
    "        \n",
    "        for idx, config in enumerate(scenario1_configs, 1):\n",
    "            method = config['method']\n",
    "            snr_db = config['snr']\n",
    "            \n",
    "            progress = f\"[{idx}/{total_s1}]\"\n",
    "            \n",
    "            try:\n",
    "                mixed_audio, used_noise, actual_snr = mix_audio_with_snr(audio_clean, audio_noise_uploaded, snr_db)\n",
    "                \n",
    "                if method == 'deterministic':\n",
    "                    method_label = \"Deterministic (DTLN)\"\n",
    "                elif method == 'traditional_manual':\n",
    "                    method_label = f\"Traditional-Manual ({config['dsp_method'].replace('_', ' ').title()})\"\n",
    "                else:\n",
    "                    method_label = \"Traditional-Library (noisereduce)\"\n",
    "                \n",
    "                print(f\"{progress} {method_label:<50} | SNR={actual_snr:6.2f}dB\", end='')\n",
    "                \n",
    "                baseline = calculate_metrics(audio_clean, mixed_audio, SAMPLE_RATE)\n",
    "                \n",
    "                start = time.time()\n",
    "                if method == 'deterministic':\n",
    "                    audio_proc = process_dtln(mixed_audio)\n",
    "                elif method == 'traditional_manual':\n",
    "                    if config['dsp_method'] == 'spectral_subtraction':\n",
    "                        audio_proc = spectral_subtraction_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "                    else:\n",
    "                        audio_proc = wiener_filter_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "                else:\n",
    "                    audio_proc = process_traditional_library(mixed_audio, sr=SAMPLE_RATE)\n",
    "                proc_time = time.time() - start\n",
    "                \n",
    "                m = calculate_metrics(audio_clean, audio_proc, SAMPLE_RATE)\n",
    "                \n",
    "                stoi_improvement = m['stoi'] - baseline['stoi']\n",
    "                pesq_improvement = m['pesq'] - baseline['pesq']\n",
    "                \n",
    "                print(f\" | STOI: {baseline['stoi']:.3f}‚Üí{m['stoi']:.3f} (Œî{stoi_improvement:+.3f}) | PESQ: {baseline['pesq']:.2f}‚Üí{m['pesq']:.2f} (Œî{pesq_improvement:+.2f})\")\n",
    "                \n",
    "                realworld_results.append({\n",
    "                    'Method': method_label,\n",
    "                    'Noise_Source': 'Uploaded',\n",
    "                    'Target_SNR_dB': snr_db,\n",
    "                    'Actual_SNR_dB': actual_snr,\n",
    "                    'Baseline_STOI': baseline['stoi'],\n",
    "                    'Baseline_PESQ': baseline['pesq'],\n",
    "                    'Processed_STOI': m['stoi'],\n",
    "                    'Processed_PESQ': m['pesq'],\n",
    "                    'STOI_Improvement': stoi_improvement,\n",
    "                    'PESQ_Improvement': pesq_improvement,\n",
    "                    'Baseline_MSE': baseline['mse'],\n",
    "                    'Processed_MSE': m['mse'],\n",
    "                    'MSE_Improvement': baseline['mse'] - m['mse'],\n",
    "                    'Baseline_MRE': baseline['mre'],\n",
    "                    'Processed_MRE': m['mre'],\n",
    "                    'MRE_Improvement': baseline['mre'] - m['mre'],\n",
    "                    'Processing_Time_s': proc_time,\n",
    "                })\n",
    "                \n",
    "                fname = f\"realworld_{method}_{config.get('dsp_method', 'dtln')}_{snr_db:.0f}dB\"\n",
    "                sf.write(f'results/audio/{fname}_processed.wav', audio_proc, SAMPLE_RATE)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\" ‚ùå Error: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"\\n‚úÖ Scenario 1 completed: {len(realworld_results)} results\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  SKIPPED: No uploaded noise file provided\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # SCENARIO 2: SYNTHETIC COMPARISON (Generated Noise)\n",
    "    # ============================================================================\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"üî¨ SCENARIO 2: SYNTHETIC COMPARISON (Using Generated Noise)\")\n",
    "    print(\"=\"*100)\n",
    "    print(\"Comparing: Stochastic (DTLN) vs Traditional-Manual (Both DSP) vs Traditional-Library\")\n",
    "    print(\"Noise Sources: Gaussian, White, Mixed\")\n",
    "    print(f\"SNR Levels: {SNR_LEVELS}\")\n",
    "    print()\n",
    "    \n",
    "    synthetic_results = []\n",
    "    scenario2_configs = []\n",
    "    noise_types = ['gaussian', 'white', 'mixed']\n",
    "    \n",
    "    # Stochastic (DTLN)\n",
    "    for noise_type in noise_types:\n",
    "        for snr in SNR_LEVELS:\n",
    "            scenario2_configs.append({\n",
    "                'method': 'stochastic',\n",
    "                'snr': snr,\n",
    "                'noise_type': noise_type\n",
    "            })\n",
    "    \n",
    "    # Traditional-Manual: BOTH Spectral Subtraction AND Wiener Filter\n",
    "    for dsp_algo in ['spectral_subtraction', 'wiener']:\n",
    "        for noise_type in noise_types:\n",
    "            for snr in SNR_LEVELS:\n",
    "                scenario2_configs.append({\n",
    "                    'method': 'traditional_manual',\n",
    "                    'snr': snr,\n",
    "                    'noise_type': noise_type,\n",
    "                    'dsp_method': dsp_algo\n",
    "                })\n",
    "    \n",
    "    # Traditional-Library\n",
    "    for noise_type in noise_types:\n",
    "        for snr in SNR_LEVELS:\n",
    "            scenario2_configs.append({\n",
    "                'method': 'traditional_library',\n",
    "                'snr': snr,\n",
    "                'noise_type': noise_type\n",
    "            })\n",
    "    \n",
    "    total_s2 = len(scenario2_configs)\n",
    "    print(f\"üîÑ Running {total_s2} experiments...\")\n",
    "    print(f\"   - Stochastic (DTLN): {len(noise_types) * len(SNR_LEVELS)} configs\")\n",
    "    print(f\"   - Traditional-Manual (Spectral Subtraction): {len(noise_types) * len(SNR_LEVELS)} configs\")\n",
    "    print(f\"   - Traditional-Manual (Wiener Filter): {len(noise_types) * len(SNR_LEVELS)} configs\")\n",
    "    print(f\"   - Traditional-Library (noisereduce): {len(noise_types) * len(SNR_LEVELS)} configs\")\n",
    "    print()\n",
    "    \n",
    "    for idx, config in enumerate(scenario2_configs, 1):\n",
    "        method = config['method']\n",
    "        snr_db = config['snr']\n",
    "        noise_type = config['noise_type']\n",
    "        \n",
    "        progress = f\"[{idx}/{total_s2}]\"\n",
    "        \n",
    "        try:\n",
    "            # Generate noisy audio\n",
    "            if noise_type == 'gaussian':\n",
    "                mixed_audio, used_noise, actual_snr = add_gaussian_noise(audio_clean, snr_db)\n",
    "                noise_label = \"Gaussian\"\n",
    "            elif noise_type == 'white':\n",
    "                mixed_audio, used_noise, actual_snr = add_white_noise(audio_clean, snr_db)\n",
    "                noise_label = \"White\"\n",
    "            elif noise_type == 'mixed':\n",
    "                if audio_noise_uploaded is not None:\n",
    "                    noise_gaussian = add_gaussian_noise(audio_clean, snr_db)[1]\n",
    "                    noise_white = add_white_noise(audio_clean, snr_db)[1]\n",
    "                    noise_uploaded_scaled = mix_audio_with_snr(audio_clean, audio_noise_uploaded, snr_db)[1]\n",
    "                    used_noise = (noise_gaussian + noise_white + noise_uploaded_scaled) / 3.0\n",
    "                else:\n",
    "                    noise_gaussian = add_gaussian_noise(audio_clean, snr_db)[1]\n",
    "                    noise_white = add_white_noise(audio_clean, snr_db)[1]\n",
    "                    used_noise = (noise_gaussian + noise_white) / 2.0\n",
    "                mixed_audio = audio_clean + used_noise\n",
    "                actual_snr = calculate_snr_db(audio_clean, mixed_audio)\n",
    "                noise_label = \"Mixed\"\n",
    "            \n",
    "            if method == 'stochastic':\n",
    "                method_label = \"Stochastic (DTLN)\"\n",
    "            elif method == 'traditional_manual':\n",
    "                method_label = f\"Traditional-Manual ({config['dsp_method'].replace('_', ' ').title()})\"\n",
    "            else:\n",
    "                method_label = \"Traditional-Library (noisereduce)\"\n",
    "            \n",
    "            print(f\"{progress} {method_label:<50} | {noise_label:<10} | SNR={actual_snr:6.2f}dB\", end='')\n",
    "            \n",
    "            baseline = calculate_metrics(audio_clean, mixed_audio, SAMPLE_RATE)\n",
    "            \n",
    "            start = time.time()\n",
    "            if method == 'stochastic':\n",
    "                audio_proc = process_dtln(mixed_audio)\n",
    "            elif method == 'traditional_manual':\n",
    "                if config['dsp_method'] == 'spectral_subtraction':\n",
    "                    audio_proc = spectral_subtraction_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "                else:\n",
    "                    audio_proc = wiener_filter_manual(mixed_audio, sr=SAMPLE_RATE)\n",
    "            else:\n",
    "                audio_proc = process_traditional_library(mixed_audio, sr=SAMPLE_RATE)\n",
    "            proc_time = time.time() - start\n",
    "            \n",
    "            m = calculate_metrics(audio_clean, audio_proc, SAMPLE_RATE)\n",
    "            \n",
    "            stoi_improvement = m['stoi'] - baseline['stoi']\n",
    "            pesq_improvement = m['pesq'] - baseline['pesq']\n",
    "            \n",
    "            print(f\" | STOI: {baseline['stoi']:.3f}‚Üí{m['stoi']:.3f} (Œî{stoi_improvement:+.3f})\")\n",
    "            \n",
    "            synthetic_results.append({\n",
    "                'Method': method_label,\n",
    "                'Noise_Type': noise_label,\n",
    "                'Target_SNR_dB': snr_db,\n",
    "                'Actual_SNR_dB': actual_snr,\n",
    "                'Baseline_STOI': baseline['stoi'],\n",
    "                'Baseline_PESQ': baseline['pesq'],\n",
    "                'Processed_STOI': m['stoi'],\n",
    "                'Processed_PESQ': m['pesq'],\n",
    "                'STOI_Improvement': stoi_improvement,\n",
    "                'PESQ_Improvement': pesq_improvement,\n",
    "                'Baseline_MSE': baseline['mse'],\n",
    "                'Processed_MSE': m['mse'],\n",
    "                'MSE_Improvement': baseline['mse'] - m['mse'],\n",
    "                'Baseline_MRE': baseline['mre'],\n",
    "                'Processed_MRE': m['mre'],\n",
    "                'MRE_Improvement': baseline['mre'] - m['mre'],\n",
    "                'Processing_Time_s': proc_time,\n",
    "            })\n",
    "            \n",
    "            fname = f\"synthetic_{method}_{config.get('dsp_method', 'dtln')}_{noise_label}_{snr_db:.0f}dB\"\n",
    "            sf.write(f'results/audio/{fname}_processed.wav', audio_proc, SAMPLE_RATE)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" ‚ùå Error: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Scenario 2 completed: {len(synthetic_results)} results\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # EXPORT RESULTS TO SEPARATE EXCEL FILES\n",
    "    # ============================================================================\n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"üìä EXPORTING RESULTS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Scenario 1: Real-world\n",
    "    if len(realworld_results) > 0:\n",
    "        df_rw = pd.DataFrame(realworld_results)\n",
    "        numeric_cols = df_rw.select_dtypes(include=[np.number]).columns\n",
    "        df_rw[numeric_cols] = df_rw[numeric_cols].round(4)\n",
    "        \n",
    "        excel_rw = 'results/scenario1_realworld_comparison.xlsx'\n",
    "        with pd.ExcelWriter(excel_rw, engine='openpyxl') as writer:\n",
    "            df_rw.to_excel(writer, sheet_name='All_Results', index=False)\n",
    "            \n",
    "            summary_method = df_rw.groupby('Method')[['Baseline_STOI', 'Processed_STOI',\n",
    "                                                       'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                       'Baseline_MSE', 'Processed_MSE',\n",
    "                                                       'Baseline_MRE', 'Processed_MRE']].agg(['mean', 'std']).round(4)\n",
    "            summary_method.to_excel(writer, sheet_name='Summary_By_Method')\n",
    "            \n",
    "            summary_snr = df_rw.groupby('Actual_SNR_dB')[['Baseline_STOI', 'Processed_STOI',\n",
    "                                                           'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                           'Baseline_MSE', 'Processed_MSE',\n",
    "                                                           'Baseline_MRE', 'Processed_MRE']].mean().round(4)\n",
    "            summary_snr.to_excel(writer, sheet_name='Summary_By_SNR')\n",
    "        \n",
    "        print(f\"‚úÖ Scenario 1 exported: {excel_rw}\")\n",
    "    \n",
    "    # Scenario 2: Synthetic\n",
    "    if len(synthetic_results) > 0:\n",
    "        df_syn = pd.DataFrame(synthetic_results)\n",
    "        numeric_cols = df_syn.select_dtypes(include=[np.number]).columns\n",
    "        df_syn[numeric_cols] = df_syn[numeric_cols].round(4)\n",
    "        \n",
    "        excel_syn = 'results/scenario2_synthetic_comparison.xlsx'\n",
    "        with pd.ExcelWriter(excel_syn, engine='openpyxl') as writer:\n",
    "            df_syn.to_excel(writer, sheet_name='All_Results', index=False)\n",
    "            \n",
    "            summary_method = df_syn.groupby('Method')[['Baseline_STOI', 'Processed_STOI',\n",
    "                                                        'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                        'Baseline_MSE', 'Processed_MSE',\n",
    "                                                        'Baseline_MRE', 'Processed_MRE']].agg(['mean', 'std']).round(4)\n",
    "            summary_method.to_excel(writer, sheet_name='Summary_By_Method')\n",
    "            \n",
    "            summary_noise = df_syn.groupby('Noise_Type')[['Baseline_STOI', 'Processed_STOI',\n",
    "                                                           'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                           'Baseline_MSE', 'Processed_MSE',\n",
    "                                                           'Baseline_MRE', 'Processed_MRE']].mean().round(4)\n",
    "            summary_noise.to_excel(writer, sheet_name='Summary_By_Noise')\n",
    "            \n",
    "            summary_snr = df_syn.groupby('Actual_SNR_dB')[['Baseline_STOI', 'Processed_STOI',\n",
    "                                                            'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                            'Baseline_MSE', 'Processed_MSE',\n",
    "                                                            'Baseline_MRE', 'Processed_MRE']].mean().round(4)\n",
    "            summary_snr.to_excel(writer, sheet_name='Summary_By_SNR')\n",
    "        \n",
    "        print(f\"‚úÖ Scenario 2 exported: {excel_syn}\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # VISUALIZATIONS: SCENARIO 1 - REAL-WORLD\n",
    "    # ============================================================================\n",
    "    if len(realworld_results) > 0:\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(\"üìà SCENARIO 1: REAL-WORLD VISUALIZATIONS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Display scoring table\n",
    "        print(f\"\\n{'Method':<50} {'SNR':<7} {'Baseline Scores (STOI/PESQ/MSE/MRE)':<50} {'Processed Scores (STOI/PESQ/MSE/MRE)':<50}\")\n",
    "        print(\"=\"*165)\n",
    "        for r in realworld_results:\n",
    "            base_scores = f\"{r['Baseline_STOI']:.3f} / {r['Baseline_PESQ']:.2f} / {r['Baseline_MSE']:.4f} / {r['Baseline_MRE']:.3f}\"\n",
    "            proc_scores = f\"{r['Processed_STOI']:.3f} / {r['Processed_PESQ']:.2f} / {r['Processed_MSE']:.4f} / {r['Processed_MRE']:.3f}\"\n",
    "            print(f\"{r['Method']:<50} {r['Actual_SNR_dB']:<7.2f} {base_scores:<50} {proc_scores:<50}\")\n",
    "        print(\"=\"*165)\n",
    "        \n",
    "        # Line plots: Baseline vs Processed across SNR\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "        fig.suptitle('Scenario 1: Real-world Noise - Metrics Scoring Across SNR Levels', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        color_map = {\n",
    "            'Deterministic (DTLN)': '#3b82f6',\n",
    "            'Traditional-Manual (Spectral Subtraction)': '#f59e0b',\n",
    "            'Traditional-Manual (Wiener Filter)': '#10b981',\n",
    "            'Traditional-Library (noisereduce)': '#ef4444'\n",
    "        }\n",
    "        \n",
    "        # STOI Comparison\n",
    "        ax = axes[0, 0]\n",
    "        for method in df_rw['Method'].unique():\n",
    "            method_data = df_rw[df_rw['Method'] == method].sort_values('Actual_SNR_dB')\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Baseline_STOI'], \n",
    "                   linestyle='--', alpha=0.5, color=color_map.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Processed_STOI'], \n",
    "                   marker='o', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('STOI Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('STOI: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.axhline(y=0.7, color='green', linestyle=':', alpha=0.5, label='Good threshold')\n",
    "        \n",
    "        # PESQ Comparison\n",
    "        ax = axes[0, 1]\n",
    "        for method in df_rw['Method'].unique():\n",
    "            method_data = df_rw[df_rw['Method'] == method].sort_values('Actual_SNR_dB')\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Baseline_PESQ'],\n",
    "                   linestyle='--', alpha=0.5, color=color_map.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Processed_PESQ'],\n",
    "                   marker='s', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('PESQ Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('PESQ: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([-0.5, 4.5])\n",
    "        ax.axhline(y=2.5, color='green', linestyle=':', alpha=0.5, label='Good threshold')\n",
    "        \n",
    "        # MSE Comparison (log scale)\n",
    "        ax = axes[1, 0]\n",
    "        for method in df_rw['Method'].unique():\n",
    "            method_data = df_rw[df_rw['Method'] == method].sort_values('Actual_SNR_dB')\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Baseline_MSE'],\n",
    "                   linestyle='--', alpha=0.5, color=color_map.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Processed_MSE'],\n",
    "                   marker='^', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('MSE Score (log scale)', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('MSE: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "        ax.axhline(y=0.01, color='green', linestyle=':', alpha=0.5, label='Good threshold')\n",
    "        \n",
    "        # MRE Comparison\n",
    "        ax = axes[1, 1]\n",
    "        for method in df_rw['Method'].unique():\n",
    "            method_data = df_rw[df_rw['Method'] == method].sort_values('Actual_SNR_dB')\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Baseline_MRE'],\n",
    "                   linestyle='--', alpha=0.5, color=color_map.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data['Actual_SNR_dB'], method_data['Processed_MRE'],\n",
    "                   marker='d', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('MRE Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('MRE: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 10])\n",
    "        ax.axhline(y=0.5, color='green', linestyle=':', alpha=0.5, label='Good threshold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/scenario1_realworld_comparison.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Bar chart: Method comparison\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "        fig.suptitle('Scenario 1: Average Scores by Method', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        method_avg = df_rw.groupby('Method')[['Baseline_STOI', 'Processed_STOI', \n",
    "                                                'Baseline_PESQ', 'Processed_PESQ',\n",
    "                                                'Baseline_MSE', 'Processed_MSE',\n",
    "                                                'Baseline_MRE', 'Processed_MRE']].mean()\n",
    "        \n",
    "        metrics_to_plot = [\n",
    "            ('STOI', ['Baseline_STOI', 'Processed_STOI'], axes[0, 0]),\n",
    "            ('PESQ', ['Baseline_PESQ', 'Processed_PESQ'], axes[0, 1]),\n",
    "            ('MSE', ['Baseline_MSE', 'Processed_MSE'], axes[1, 0]),\n",
    "            ('MRE', ['Baseline_MRE', 'Processed_MRE'], axes[1, 1])\n",
    "        ]\n",
    "        \n",
    "        for metric_name, cols, ax in metrics_to_plot:\n",
    "            x = np.arange(len(method_avg))\n",
    "            width = 0.35\n",
    "            \n",
    "            bars1 = ax.bar(x - width/2, method_avg[cols[0]], width, label='Baseline',\n",
    "                          color='#94a3b8', edgecolor='black', linewidth=1)\n",
    "            bars2 = ax.bar(x + width/2, method_avg[cols[1]], width, label='Processed',\n",
    "                          color=[color_map.get(m, '#666') for m in method_avg.index],\n",
    "                          edgecolor='black', linewidth=1)\n",
    "            \n",
    "            ax.set_xlabel('Method', fontweight='bold')\n",
    "            ax.set_ylabel(f'{metric_name} Score', fontweight='bold')\n",
    "            ax.set_title(f'Average {metric_name} Scores', fontweight='bold')\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(method_avg.index, rotation=20, ha='right', fontsize=8)\n",
    "            ax.legend()\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for bars in [bars1, bars2]:\n",
    "                for bar in bars:\n",
    "                    height = bar.get_height()\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{height:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/scenario1_realworld_methods.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Scenario 1 visualizations saved\")\n",
    "    \n",
    "    # ============================================================================\n",
    "    # VISUALIZATIONS: SCENARIO 2 - SYNTHETIC\n",
    "    # ============================================================================\n",
    "    if len(synthetic_results) > 0:\n",
    "        print(f\"\\n{'='*100}\")\n",
    "        print(\"üìà SCENARIO 2: SYNTHETIC VISUALIZATIONS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Display scoring table (sample)\n",
    "        print(f\"\\n{'Method':<50} {'Noise':<10} {'SNR':<7} {'Baseline (STOI/PESQ)':<25} {'Processed (STOI/PESQ)':<25}\")\n",
    "        print(\"=\"*120)\n",
    "        for r in synthetic_results[:12]:\n",
    "            base_scores = f\"{r['Baseline_STOI']:.3f} / {r['Baseline_PESQ']:.2f}\"\n",
    "            proc_scores = f\"{r['Processed_STOI']:.3f} / {r['Processed_PESQ']:.2f}\"\n",
    "            print(f\"{r['Method']:<50} {r['Noise_Type']:<10} {r['Actual_SNR_dB']:<7.2f} {base_scores:<25} {proc_scores:<25}\")\n",
    "        if len(synthetic_results) > 12:\n",
    "            print(f\"... ({len(synthetic_results) - 12} more rows)\")\n",
    "        print(\"=\"*120)\n",
    "        \n",
    "        # Line plots: Similar to Scenario 1 but averaged across noise types\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "        fig.suptitle('Scenario 2: Synthetic Noise - Average Metrics Scoring Across SNR Levels', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        color_map_syn = {\n",
    "            'Stochastic (DTLN)': '#9333ea',\n",
    "            'Traditional-Manual (Spectral Subtraction)': '#f59e0b',\n",
    "            'Traditional-Manual (Wiener Filter)': '#10b981',\n",
    "            'Traditional-Library (noisereduce)': '#ef4444'\n",
    "        }\n",
    "        \n",
    "        # STOI\n",
    "        ax = axes[0, 0]\n",
    "        for method in df_syn['Method'].unique():\n",
    "            method_data_base = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Baseline_STOI'].mean()\n",
    "            method_data_proc = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Processed_STOI'].mean()\n",
    "            ax.plot(method_data_base.index, method_data_base.values,\n",
    "                   linestyle='--', alpha=0.5, color=color_map_syn.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data_proc.index, method_data_proc.values,\n",
    "                   marker='o', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map_syn.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('STOI Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('STOI: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.axhline(y=0.7, color='green', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        # PESQ\n",
    "        ax = axes[0, 1]\n",
    "        for method in df_syn['Method'].unique():\n",
    "            method_data_base = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Baseline_PESQ'].mean()\n",
    "            method_data_proc = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Processed_PESQ'].mean()\n",
    "            ax.plot(method_data_base.index, method_data_base.values,\n",
    "                   linestyle='--', alpha=0.5, color=color_map_syn.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data_proc.index, method_data_proc.values,\n",
    "                   marker='s', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map_syn.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('PESQ Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('PESQ: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([-0.5, 4.5])\n",
    "        ax.axhline(y=2.5, color='green', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        # MSE (log scale)\n",
    "        ax = axes[1, 0]\n",
    "        for method in df_syn['Method'].unique():\n",
    "            method_data_base = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Baseline_MSE'].mean()\n",
    "            method_data_proc = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Processed_MSE'].mean()\n",
    "            ax.plot(method_data_base.index, method_data_base.values,\n",
    "                   linestyle='--', alpha=0.5, color=color_map_syn.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data_proc.index, method_data_proc.values,\n",
    "                   marker='^', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map_syn.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('MSE Score (log scale)', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('MSE: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_yscale('log')\n",
    "        ax.axhline(y=0.01, color='green', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        # MRE\n",
    "        ax = axes[1, 1]\n",
    "        for method in df_syn['Method'].unique():\n",
    "            method_data_base = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Baseline_MRE'].mean()\n",
    "            method_data_proc = df_syn[df_syn['Method'] == method].groupby('Actual_SNR_dB')['Processed_MRE'].mean()\n",
    "            ax.plot(method_data_base.index, method_data_base.values,\n",
    "                   linestyle='--', alpha=0.5, color=color_map_syn.get(method, '#666666'), linewidth=1.5)\n",
    "            ax.plot(method_data_proc.index, method_data_proc.values,\n",
    "                   marker='d', label=method, linewidth=2.5, markersize=8,\n",
    "                   color=color_map_syn.get(method, '#666666'))\n",
    "        ax.set_xlabel('SNR (dB)', fontweight='bold', fontsize=11)\n",
    "        ax.set_ylabel('MRE Score', fontweight='bold', fontsize=11)\n",
    "        ax.set_title('MRE: Baseline (dashed) vs Processed (solid)', fontweight='bold', fontsize=12)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim([0, 10])\n",
    "        ax.axhline(y=0.5, color='green', linestyle=':', alpha=0.5)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/scenario2_synthetic_comparison.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        # Bar chart by noise type\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        fig.suptitle('Scenario 2: Processed STOI Scores by Noise Type', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        for idx, noise_type in enumerate(['Gaussian', 'White', 'Mixed']):\n",
    "            ax = axes[idx]\n",
    "            noise_data = df_syn[df_syn['Noise_Type'] == noise_type].groupby('Method')['Processed_STOI'].mean().sort_values(ascending=False)\n",
    "            \n",
    "            bars = ax.bar(range(len(noise_data)), noise_data.values,\n",
    "                         color=[color_map_syn.get(m, '#666') for m in noise_data.index],\n",
    "                         edgecolor='black', linewidth=1.5)\n",
    "            ax.set_xticks(range(len(noise_data)))\n",
    "            ax.set_xticklabels(noise_data.index, rotation=20, ha='right', fontsize=8)\n",
    "            ax.set_ylabel('STOI Score', fontweight='bold')\n",
    "            ax.set_title(f'{noise_type} Noise', fontweight='bold')\n",
    "            ax.set_ylim([0, 1])\n",
    "            ax.grid(axis='y', alpha=0.3)\n",
    "            ax.axhline(y=0.7, color='green', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                       f'{height:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/scenario2_synthetic_by_noise.png', dpi=150, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Scenario 2 visualizations saved\")\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(\"üéâ BATCH EVALUATION COMPLETED\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"‚úÖ Scenario 1 (Real-world): {len(realworld_results)} experiments\")\n",
    "    print(f\"‚úÖ Scenario 2 (Synthetic): {len(synthetic_results)} experiments\")\n",
    "    print(f\"\\nüìÅ Files saved:\")\n",
    "    if len(realworld_results) > 0:\n",
    "        print(f\"   ‚Ä¢ results/scenario1_realworld_comparison.xlsx\")\n",
    "        print(f\"   ‚Ä¢ results/scenario1_realworld_comparison.png\")\n",
    "        print(f\"   ‚Ä¢ results/scenario1_realworld_methods.png\")\n",
    "    if len(synthetic_results) > 0:\n",
    "        print(f\"   ‚Ä¢ results/scenario2_synthetic_comparison.xlsx\")\n",
    "        print(f\"   ‚Ä¢ results/scenario2_synthetic_comparison.png\")\n",
    "        print(f\"   ‚Ä¢ results/scenario2_synthetic_by_noise.png\")\n",
    "    print(f\"   ‚Ä¢ results/audio/*.wav (processed audio files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f78669",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üì• Download Results\n",
    "**One-click download of all generated files**\n",
    "\n",
    "Downloads a ZIP package containing:\n",
    "- ‚úÖ Excel files (Scenario 1 & 2 with multiple sheets)\n",
    "- ‚úÖ Visualizations (performance charts & improvement graphs)\n",
    "- ‚úÖ Processed audio files (all experiments)\n",
    "- ‚úÖ Single experiment results (if executed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bcd57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title üì¶ Create & Download Results Package { display-mode: \"form\" }\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üì• **Download Control**\n",
    "download_results = False  #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### üìù **Package Contents:**\n",
    "#@markdown - Excel: scenario1_realworld_comparison.xlsx\n",
    "#@markdown - Excel: scenario2_synthetic_comparison.xlsx\n",
    "#@markdown - Images: performance & improvement charts (PNG)\n",
    "#@markdown - Audio: processed WAV files\n",
    "#@markdown - Single: individual experiment results\n",
    "\n",
    "if download_results:\n",
    "    import zipfile\n",
    "    from datetime import datetime\n",
    "    \n",
    "    print(\"üì¶ Creating download package...\")\n",
    "    \n",
    "    # Create timestamp for unique filename\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    zip_filename = f'dtln_evaluation_results_{timestamp}.zip'\n",
    "    \n",
    "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        # Add Excel files\n",
    "        for excel_file in ['results/scenario1_realworld_comparison.xlsx', \n",
    "                          'results/scenario2_synthetic_comparison.xlsx']:\n",
    "            if os.path.exists(excel_file):\n",
    "                zipf.write(excel_file, os.path.basename(excel_file))\n",
    "                print(f\"   ‚úì {os.path.basename(excel_file)}\")\n",
    "        \n",
    "        # Add visualizations\n",
    "        for viz_file in ['results/scenario1_realworld_performance.png',\n",
    "                        'results/scenario1_realworld_improvements.png',\n",
    "                        'results/scenario2_synthetic_performance.png',\n",
    "                        'results/scenario2_synthetic_improvements.png']:\n",
    "            if os.path.exists(viz_file):\n",
    "                zipf.write(viz_file, os.path.join('visualizations', os.path.basename(viz_file)))\n",
    "                print(f\"   ‚úì visualizations/{os.path.basename(viz_file)}\")\n",
    "        \n",
    "        # Add processed audio files\n",
    "        audio_dir = 'results/audio'\n",
    "        if os.path.exists(audio_dir):\n",
    "            for audio_file in os.listdir(audio_dir):\n",
    "                if audio_file.endswith('.wav'):\n",
    "                    zipf.write(os.path.join(audio_dir, audio_file), \n",
    "                             os.path.join('audio', audio_file))\n",
    "            print(f\"   ‚úì {len(os.listdir(audio_dir))} audio files\")\n",
    "        \n",
    "        # Add single experiment results if exist\n",
    "        if os.path.exists('results/spectrograms'):\n",
    "            for spec_file in os.listdir('results/spectrograms'):\n",
    "                if spec_file.startswith('single_'):\n",
    "                    zipf.write(os.path.join('results/spectrograms', spec_file),\n",
    "                             os.path.join('single_experiment', spec_file))\n",
    "        \n",
    "        if os.path.exists('results/metrics'):\n",
    "            for metric_file in os.listdir('results/metrics'):\n",
    "                if metric_file.startswith('single_'):\n",
    "                    zipf.write(os.path.join('results/metrics', metric_file),\n",
    "                             os.path.join('single_experiment', metric_file))\n",
    "        \n",
    "        if os.path.exists('outputs'):\n",
    "            for output_file in os.listdir('outputs'):\n",
    "                if output_file.startswith('single_'):\n",
    "                    zipf.write(os.path.join('outputs', output_file),\n",
    "                             os.path.join('single_experiment', output_file))\n",
    "    \n",
    "    file_size = os.path.getsize(zip_filename) / (1024 * 1024)\n",
    "    print(f\"\\n‚úÖ Package created: {zip_filename} ({file_size:.2f} MB)\")\n",
    "    print(f\"\\nüì• Downloading...\")\n",
    "    files.download(zip_filename)\n",
    "    print(f\"‚úÖ Download started!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6c24d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Evaluation Framework Documentation\n",
    "\n",
    "### **Two Independent Scenarios:**\n",
    "\n",
    "#### **üåç Scenario 1: Real-world Comparison**\n",
    "**Objective:** Evaluate performance on actual recorded noise\n",
    "\n",
    "**Methods Evaluated:**\n",
    "- Deterministic (DTLN) - 4 SNR levels\n",
    "- Traditional-Manual (Spectral Subtraction) - 4 SNR levels\n",
    "- Traditional-Manual (Wiener Filter) - 4 SNR levels\n",
    "- Traditional-Library (noisereduce) - 4 SNR levels\n",
    "\n",
    "**Total:** 16 experiments (4 methods √ó 4 SNR levels)\n",
    "\n",
    "**Noise Source:** Single uploaded noise file (identical for all methods)\n",
    "\n",
    "**SNR Levels:** -5, 0, 5, 10 dB\n",
    "\n",
    "---\n",
    "\n",
    "#### **üî¨ Scenario 2: Synthetic Comparison**\n",
    "**Objective:** Evaluate robustness across different noise types\n",
    "\n",
    "**Methods Evaluated:**\n",
    "- Stochastic (DTLN) - 3 noise types √ó 4 SNR levels = 12\n",
    "- Traditional-Manual (Spectral Subtraction) - 3 noise types √ó 4 SNR levels = 12\n",
    "- Traditional-Manual (Wiener Filter) - 3 noise types √ó 4 SNR levels = 12\n",
    "- Traditional-Library (noisereduce) - 3 noise types √ó 4 SNR levels = 12\n",
    "\n",
    "**Total:** 48 experiments (4 methods √ó 3 noise types √ó 4 SNR levels)\n",
    "\n",
    "**Noise Types:** Gaussian, White, Mixed (synthetic)\n",
    "\n",
    "**SNR Levels:** -5, 0, 5, 10 dB\n",
    "\n",
    "---\n",
    "\n",
    "### **Evaluation Metrics:**\n",
    "\n",
    "| Metric | Description | Range | Better |\n",
    "|--------|-------------|-------|--------|\n",
    "| **STOI** | Short-Time Objective Intelligibility | 0-1 | Higher ‚Üë |\n",
    "| **PESQ** | Perceptual Evaluation of Speech Quality | -0.5 to 4.5 | Higher ‚Üë |\n",
    "| **MSE** | Mean Squared Error | 0-‚àû | Lower ‚Üì |\n",
    "| **MRE** | Mean Relative Error (masked) | 0-10 | Lower ‚Üì |\n",
    "\n",
    "---\n",
    "\n",
    "### **Method References:**\n",
    "\n",
    "#### **1. Deterministic (DTLN)**\n",
    "- **Paper:** Westhausen & Meyer (2020). \"Dual-signal transformation LSTM network for real-time noise suppression\"\n",
    "- **Noise:** Fixed uploaded noise (deterministic)\n",
    "- **Scenario:** Real-world only\n",
    "\n",
    "#### **2. Stochastic (DTLN)**\n",
    "- **Paper:** Same as Deterministic\n",
    "- **Noise:** Random synthetic noise (stochastic)\n",
    "- **Scenario:** Synthetic only\n",
    "\n",
    "#### **3. Traditional-Manual (DSP)**\n",
    "**Spectral Subtraction:**\n",
    "- **Paper:** Boll (1979). \"Suppression of acoustic noise in speech using spectral subtraction\"\n",
    "- **Parameters:** Œ±=2.0 (over-subtraction), Œ≤=0.01 (spectral floor)\n",
    "\n",
    "**Wiener Filter:**\n",
    "- **Paper:** Lim & Oppenheim (1979). \"Enhancement and bandwidth compression of noisy speech\"\n",
    "- **Method:** SNR-based gain estimation with minimum gain threshold (0.1)\n",
    "\n",
    "**Noise Estimation:** First 10 frames (blind estimation)\n",
    "\n",
    "#### **4. Traditional-Library (noisereduce)**\n",
    "- **Library:** https://github.com/timsainb/noisereduce\n",
    "- **Algorithm:** Spectral Gating (similar to Audacity)\n",
    "- **Scenarios:** Both Real-world and Synthetic\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Features:**\n",
    "\n",
    "‚úÖ **Single Experiment Mode:** Full visualization with before/after waveforms, spectrograms, overlay, and metrics\n",
    "\n",
    "‚úÖ **Batch Processing:** All combinations of Traditional-Manual methods (Spectral Subtraction AND Wiener Filter)\n",
    "\n",
    "‚úÖ **Fair Comparison:** All methods tested on identical noise conditions within each scenario\n",
    "\n",
    "‚úÖ **Download Package:** One-click download of all Excel files, visualizations, and audio files\n",
    "\n",
    "‚úÖ **Grand Total:** 64 experiments (16 real-world + 48 synthetic)\n",
    "\n",
    "‚úÖ **Auto-Export:** Results saved to Excel with multiple summary sheets\n",
    "\n",
    "‚úÖ **Blind Evaluation:** No ground truth leakage (noise estimated from audio)\n",
    "\n",
    "---\n",
    "\n",
    "### **Output Files Structure:**\n",
    "\n",
    "```\n",
    "dtln_evaluation_results_YYYYMMDD_HHMMSS.zip\n",
    "‚îú‚îÄ‚îÄ scenario1_realworld_comparison.xlsx\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ All_Results (detailed metrics)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Summary_By_Method (mean & std)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Summary_By_SNR (aggregated)\n",
    "‚îú‚îÄ‚îÄ scenario2_synthetic_comparison.xlsx\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ All_Results (detailed metrics)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Summary_By_Method (mean & std)\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ Summary_By_Noise (per noise type)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ Summary_By_SNR (aggregated)\n",
    "‚îú‚îÄ‚îÄ visualizations/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ scenario1_realworld_performance.png\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ scenario1_realworld_improvements.png\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ scenario2_synthetic_performance.png\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ scenario2_synthetic_improvements.png\n",
    "‚îú‚îÄ‚îÄ audio/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ realworld_*.wav (processed audio)\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ synthetic_*.wav (processed audio)\n",
    "‚îî‚îÄ‚îÄ single_experiment/ (if single mode executed)\n",
    "    ‚îú‚îÄ‚îÄ single_*_full.png (5-row visualization)\n",
    "    ‚îú‚îÄ‚îÄ single_*_chart.png (metrics comparison)\n",
    "    ‚îú‚îÄ‚îÄ single_*_before.wav\n",
    "    ‚îî‚îÄ‚îÄ single_*_after.wav\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üìñ Usage Instructions:**\n",
    "\n",
    "1. **Install Packages** - Run cell 2 to install dependencies\n",
    "2. **Download Models** - Run cell 3 to get DTLN models\n",
    "3. **Upload Audio** - Run cell 4 to upload clean speech and noise\n",
    "4. **Load Functions** - Run cell 5 to initialize processing\n",
    "5. **Single Test** (optional) - Run cell 7 for detailed single analysis\n",
    "6. **Batch Evaluation** - Run cell 9 for comprehensive testing\n",
    "7. **Download Results** - Run cell 11 to get all outputs\n",
    "\n",
    "**üéØ Recommended Workflow:**\n",
    "- Start with Single Experiment to verify setup\n",
    "- Run Batch Evaluation for comprehensive results\n",
    "- Download package for offline analysis\n",
    "\n",
    "**‚ö° Performance Notes:**\n",
    "- Single experiment: ~5-10 seconds\n",
    "- Batch evaluation: ~10-15 minutes (64 experiments)\n",
    "- Results automatically saved during processing"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
